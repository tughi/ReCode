\ Copyright (c) 2020, Stefan Selariu

Scanner :: struct {
    source: @Source
    current_char_index: Int
    current_line: Int
    current_column: Int
    current_token: @Token
}

create_scanner :: (source: @Source) -> @Scanner {
    scanner := new Scanner
    scanner.source = source
    scanner.current_char_index = 0
    scanner.current_line = 1
    scanner.current_column = 1
    scanner.current_token = scanner.scan_token()
    return scanner
}

peek_token :: (self: @Scanner, offset: Int) -> @Token {
    if (offset < 0) {
        abort("Invalid state")
    }
    token := self.current_token
    loop {
        if (token.next_token == null) {
            token.next_token = self.scan_token()
        }
        token = token.next_token
        if (offset == 0) {
            return token
        }
        offset = offset - 1
    }
}

next_token :: (self: @Scanner) -> @Token {
    if (self.current_token.next_token == null) {
        self.current_token.next_token = self.scan_token()
    }
    self.current_token = self.current_token.next_token
    return self.current_token
}

peek_char :: (self: @Scanner) -> Int8 {
    return self.source.content[self.current_char_index]
}

next_char :: (self: @Scanner) -> Int8 {
    next_char := self.source.content[self.current_char_index]
    if (next_char != '\0') {
        self.current_char_index = self.current_char_index + 1
        if (next_char == '\n') {
            self.current_line = self.current_line + 1
            self.current_column = 1
        } else {
            self.current_column = self.current_column + 1
        }
    }
    return next_char
}

scan_token :: (self: @Scanner) -> @Token {
    token_lexeme := new String
    token_lexeme.init()

    token_location := new Source_Location
    token_location.source = self.source
    token_location.line = self.current_line
    token_location.column = self.current_column

    next_char := self.peek_char()
    if (next_char.is_identifier_start()) {
        return self.scan_identifier_token(token_lexeme, token_location)
    }
    if (next_char.is_digit()) {
        return self.scan_integer_token(token_lexeme, token_location)
    }
    if (next_char == '\'') {
        return self.scan_character_token(token_lexeme, token_location)
    }
    if (next_char == '"') {
        return self.scan_string_token(token_lexeme, token_location)
    }
    if (next_char == '\\') {
        return self.scan_comment_token(token_lexeme, token_location)
    }
    if (next_char.is_space()) {
        return self.scan_space_token(token_lexeme, token_location)
    }
    if (next_char == '\n') {
        self.next_char()
        return create_end_of_line_token(token_lexeme, token_location)
    }
    if (next_char == '\0') {
        self.next_char()
        return create_end_of_file_token(token_lexeme, token_location)
    }
    token_lexeme.append(self.next_char())
    return create_other_token(token_lexeme, token_location)
}

is_digit :: (char: Int8) -> Boolean {
    return char as Int >= '0' as Int && char as Int <= '9' as Int
}

is_identifier_start :: (char: Int8) -> Boolean {
    return char.is_letter() || char == '_'
}

is_identifier_body :: (char: Int8) -> Boolean {
    if (char.is_identifier_start()) {
        return true
    }
    return char.is_digit()
}

is_letter :: (char: Int8) -> Boolean {
    return (char as Int >= 'a' as Int && char as Int <= 'z' as Int) || (char as Int >= 'A' as Int && char as Int <= 'Z' as Int)
}

is_space :: (char: Int8) -> Boolean {
    return char == ' '
}

scan_character_token :: (self: @Scanner, token_lexeme: @String, token_location: @Source_Location) -> @Token {
    if (self.peek_char() != '\'') {
        abort("Invalid state")
    }

    value: Int8
    token_lexeme.append(self.next_char())
    char := self.next_char()
    token_lexeme.append(char)
    if (char == '\'') {
        return create_error_token(token_lexeme, token_location)
    }
    if (char == '\\') {
        char = self.next_char()
        token_lexeme.append(char)
        if (char.is_escape() == false) {
            return create_error_token(token_lexeme, token_location)
        }
        if (char == 'n') {
            value = '\n'
        } else if (char == '\"') {
            value = char
        } else if (char == '\'') {
            value = char
        } else if (char == '\\') {
            value = char
        } else if (char == 't') {
            value = '\t'
        } else if (char == '0') {
            value = '\0'
        } else {
            abort("Invalid state")
        }
        char = self.next_char()
        token_lexeme.append(char)
        if (char != '\'') {
            return create_error_token(token_lexeme, token_location)
        }
    } else {
        if (char == '\0' || char == '\n' || char == '\t') {
            return create_error_token(token_lexeme, token_location)
        }
        value = char
        char = self.next_char()
        token_lexeme.append(char)
        if (char != '\'') {
            return create_error_token(token_lexeme, token_location)
        }
    }
    return create_character_token(token_lexeme, token_location, value)
}

is_escape :: (char: Int8) -> Boolean {
    return char == 'n' || char == 't' || char == '\"' || char == '\'' || char == '\\' || char == '0'
}

scan_comment_token :: (self: @Scanner, token_lexeme: @String, token_location: @Source_Location) -> @Token {
    while (self.peek_char() != '\n') {
        token_lexeme.append(self.next_char())
    }
    return create_comment_token(token_lexeme, token_location)
}

scan_identifier_token :: (self: @Scanner, token_lexeme: @String, token_location: @Source_Location) -> @Token {
    while (self.peek_char().is_identifier_body()) {
        token_lexeme.append(self.next_char())
    }
    if (token_lexeme.equals("as")) {
        return create_keyword_token(token_lexeme, token_location)
    }
    if (token_lexeme.equals("break")) {
        return create_keyword_token(token_lexeme, token_location)
    }
    if (token_lexeme.equals("else")) {
        return create_keyword_token(token_lexeme, token_location)
    }
    if (token_lexeme.equals("external")) {
        return create_keyword_token(token_lexeme, token_location)
    }
    if (token_lexeme.equals("false")) {
        return create_boolean_token(token_lexeme, token_location, false)
    }
    if (token_lexeme.equals("if")) {
        return create_keyword_token(token_lexeme, token_location)
    }
    if (token_lexeme.equals("include")) {
        return create_keyword_token(token_lexeme, token_location)
    }
    if (token_lexeme.equals("loop")) {
        return create_keyword_token(token_lexeme, token_location)
    }
    if (token_lexeme.equals("new")) {
        return create_keyword_token(token_lexeme, token_location)
    }
    if (token_lexeme.equals("null")) {
        return create_null_token(token_lexeme, token_location)
    }
    if (token_lexeme.equals("return")) {
        return create_keyword_token(token_lexeme, token_location)
    }
    if (token_lexeme.equals("struct")) {
        return create_keyword_token(token_lexeme, token_location)
    }
    if (token_lexeme.equals("true")) {
        return create_boolean_token(token_lexeme, token_location, true)
    }
    if (token_lexeme.equals("while")) {
        return create_keyword_token(token_lexeme, token_location)
    }
    return create_identifier_token(token_lexeme, token_location)
}

scan_integer_token :: (self: @Scanner, token_lexeme: @String, token_location: @Source_Location) -> @Token {
    value := 0
    while (self.peek_char().is_digit()) {
        char := self.next_char()
        value = value * 10 + (char as Int - '0' as Int)
        token_lexeme.append(char)
    }
    return create_integer_token(token_lexeme, token_location, value)
}

scan_space_token :: (self: @Scanner, token_lexeme: @String, token_location: @Source_Location) -> @Token {
    count := 0
    while (self.peek_char() == ' ') {
        char := self.next_char()
        count = count + 1
        token_lexeme.append(char)
    }
    return create_space_token(token_lexeme, token_location, count)
}

scan_string_token :: (self: @Scanner, token_lexeme: @String, token_location: @Source_Location) -> @Token {
    if (self.peek_char() != '"') {
        abort("Invalid state")
    }

    value := new String
    value.init()

    token_lexeme.append(self.next_char())
    loop {
        char := self.peek_char()
        if (char == '\0' || char == '\n') {
            return create_error_token(token_lexeme, token_location)
        }
        char = self.next_char()
        token_lexeme.append(char)
        if (char == '"') {
            return create_string_token(token_lexeme, token_location, value)
        }
        if (char == '\\') {
            char = self.peek_char()
            if (char == '\0' || char == '\n') {
                return create_error_token(token_lexeme, token_location)
            }
            char = self.next_char()
            token_lexeme.append(char)
            if (char.is_escape() == false) {
                return create_error_token(token_lexeme, token_location)
            }
            if (char == 'n') {
                value.append('\n')
            } else if (char == '\"') {
                value.append(char)
            } else if (char == '\'') {
                value.append(char)
            } else if (char == '\\') {
                value.append(char)
            } else if (char == 't') {
                value.append('\t')
            } else if (char == '0') {
                value.append('\0')
            } else {
                abort("Invalid state")
            }
        } else {
            value.append(char)
        }
    }
}
