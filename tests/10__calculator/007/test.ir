type FILE = opaque

type Tokenizer = struct {
  data: ptr<u8>
  index: i32
}

type Token = struct {
  kind: i32
  value: u8
}

external $stdin: ptr<FILE>

external $stdout: ptr<FILE>

external $stderr: ptr<FILE>

$main(%argc: i32, %argv: ptr<ptr<u8>>) {
@1:
  [ %argv %argc $stdout ]
  %argc.ptr: ptr<i32> = alloc i32
  [ %argc.ptr %argv %argc $stdout ]
  store %argc.ptr %argc
  [ %argc.ptr %argv $stdout ]
  %argv.ptr: ptr<ptr<ptr<u8>>> = alloc ptr<ptr<u8>>
  [ %argc.ptr %argv.ptr %argv $stdout ]
  store %argv.ptr %argv
  [ %argc.ptr %argv.ptr $stdout ]
  %argc.1: i32 = load %argc.ptr
  [ %argc.1 %argv.ptr $stdout ]
  %1: i32 = const 2
  [ %argc.1 %1 %argv.ptr $stdout ]
  %2: bool = cmp_ne %argc.1 %1
  [ %2 %argv.ptr $stdout ]
  br %2 @2 @3
  [ %argv.ptr $stdout ]
@2:
  [ ]
  %3: i32 = const 1
  [ %3 ]
  call $exit %3
  [ ]
@3:
  [ %argv.ptr $stdout ]
  %tokenizer.ptr: ptr<Tokenizer> = alloc Tokenizer
  [ %tokenizer.ptr %argv.ptr $stdout ]
  %4: i32 = const 1
  [ %tokenizer.ptr %argv.ptr %4 $stdout ]
  %5: ptr<ptr<u8>> = offset %argv.ptr %4
  [ %tokenizer.ptr %5 $stdout ]
  %6: ptr<u8> = load %5
  [ %tokenizer.ptr %6 $stdout ]
  %7: i32 = const 0
  [ %tokenizer.ptr %7 %6 $stdout ]
  %8: Tokenizer = struct { Tokenizer.data: %6, Tokenizer.index: %7 }
  [ %tokenizer.ptr %7 %6 $stdout ]
  %9: ptr<ptr<u8>> = offset %tokenizer.ptr Tokenizer.data
  [ %tokenizer.ptr %7 %9 %6 $stdout ]
  store %9 %6
  [ %tokenizer.ptr %7 $stdout ]
  %10: ptr<i32> = offset %tokenizer.ptr Tokenizer.index
  [ %tokenizer.ptr %10 %7 $stdout ]
  store %10 %7
  [ %tokenizer.ptr $stdout ]
  %tokenizer_ref.ptr: ptr<ptr<Tokenizer>> = alloc ptr<Tokenizer>
  [ %tokenizer_ref.ptr %tokenizer.ptr $stdout ]
  store %tokenizer_ref.ptr %tokenizer.ptr
  [ %tokenizer.ptr $stdout ]
  jmp @4
  [ %tokenizer.ptr $stdout ]
@4:
  [ %tokenizer.ptr $stdout ]
  %11: bool = call $has_next_token %tokenizer.ptr
  [ %11 %tokenizer.ptr $stdout ]
  br %11 @5 @6
  [ %tokenizer.ptr $stdout ]
@5:
  [ %tokenizer.ptr $stdout ]
  %token.ptr: ptr<ptr<Token>> = alloc ptr<Token>
  [ %token.ptr %tokenizer.ptr $stdout ]
  %12: ptr<Token> = call $next_token %tokenizer.ptr
  [ %token.ptr %12 %tokenizer.ptr $stdout ]
  store %token.ptr %12
  [ %token.ptr %tokenizer.ptr $stdout ]
  %13: ptr<Token> = load %token.ptr
  [ %13 %tokenizer.ptr $stdout %token.ptr ]
  %14: ptr<i32> = offset %13 Token.kind
  [ %14 %tokenizer.ptr $stdout %token.ptr ]
  %15: i32 = load %14
  [ %15 %tokenizer.ptr $stdout %token.ptr ]
  %16: i32 = const 0
  [ %15 %16 %tokenizer.ptr $stdout %token.ptr ]
  %17: bool = cmp_eq %15 %16
  [ %17 %tokenizer.ptr $stdout %token.ptr ]
  br %17 @7 @8
  [ %tokenizer.ptr $stdout %token.ptr ]
@6:
  [ ]
  ret
  [ ]
@7:
  [ ]
  jmp @6
  [ ]
@8:
  [ %tokenizer.ptr $stdout %token.ptr ]
  %18: ptr<Token> = load %token.ptr
  [ %tokenizer.ptr $stdout %18 ]
  %19: ptr<u8> = offset %18 Token.value
  [ %tokenizer.ptr $stdout %19 ]
  %20: u8 = load %19
  [ %tokenizer.ptr %20 $stdout ]
  %21: ptr<FILE> = load $stdout
  [ %tokenizer.ptr %20 %21 $stdout ]
  %22: i32 = call $fputc %20 %21
  [ %tokenizer.ptr $stdout ]
  jmp @4
  [ %tokenizer.ptr $stdout ]
@9:
  [ %tokenizer.ptr $stdout %token.ptr ]
  jmp @8
  [ %tokenizer.ptr $stdout %token.ptr ]
}

$has_next_token(%self: ptr<Tokenizer>): bool {
@1:
  [ %self ]
  %self.ptr: ptr<ptr<Tokenizer>> = alloc ptr<Tokenizer>
  [ %self.ptr %self ]
  store %self.ptr %self
  [ %self.ptr ]
  %1: ptr<Tokenizer> = load %self.ptr
  [ %self.ptr %1 ]
  %2: ptr<ptr<u8>> = offset %1 Tokenizer.data
  [ %2 %self.ptr ]
  %3: ptr<Tokenizer> = load %self.ptr
  [ %2 %3 ]
  %4: ptr<i32> = offset %3 Tokenizer.index
  [ %2 %4 ]
  %5: i32 = load %4
  [ %2 %5 ]
  %6: ptr<u8> = offset %2 %5
  [ %6 ]
  %7: u8 = load %6
  [ %7 ]
  %8: u8 = const 0
  [ %7 %8 ]
  %9: bool = cmp_ne %7 %8
  [ %9 ]
  ret %9
  [ ]
}

$next_token(%self: ptr<Tokenizer>): ptr<Token> {
@1:
  [ %self ]
  %self.ptr: ptr<ptr<Tokenizer>> = alloc ptr<Tokenizer>
  [ %self.ptr %self ]
  store %self.ptr %self
  [ %self.ptr ]
  %value.ptr: ptr<u8> = alloc u8
  [ %value.ptr %self.ptr ]
  %1: ptr<Tokenizer> = load %self.ptr
  [ %value.ptr %self.ptr %1 ]
  %2: ptr<ptr<u8>> = offset %1 Tokenizer.data
  [ %value.ptr %self.ptr %2 ]
  %3: ptr<Tokenizer> = load %self.ptr
  [ %value.ptr %self.ptr %2 %3 ]
  %4: ptr<i32> = offset %3 Tokenizer.index
  [ %value.ptr %self.ptr %2 %4 ]
  %5: i32 = load %4
  [ %value.ptr %self.ptr %2 %5 ]
  %6: ptr<u8> = offset %2 %5
  [ %value.ptr %self.ptr %6 ]
  %7: u8 = load %6
  [ %value.ptr %self.ptr %7 ]
  store %value.ptr %7
  [ %value.ptr %self.ptr ]
  %8: ptr<Tokenizer> = load %self.ptr
  [ %value.ptr %self.ptr %8 ]
  %9: ptr<i32> = offset %8 Tokenizer.index
  [ %value.ptr %9 %self.ptr ]
  %10: ptr<Tokenizer> = load %self.ptr
  [ %value.ptr %9 %10 ]
  %11: ptr<i32> = offset %10 Tokenizer.index
  [ %value.ptr %9 %11 ]
  %12: i32 = load %11
  [ %value.ptr %9 %12 ]
  %13: i32 = const 1
  [ %value.ptr %9 %12 %13 ]
  %14: i32 = add %12 %13
  [ %value.ptr %9 %14 ]
  store %9 %14
  [ %value.ptr ]
  %15: u64 = const 5
  [ %value.ptr %15 ]
  %16: ptr<Token> = call $malloc %15
  [ %16 %value.ptr ]
  %17: i32 = const 1
  [ %16 %17 %value.ptr ]
  %value.1: u8 = load %value.ptr
  [ %16 %value.1 %17 ]
  %18: Token = struct { Token.kind: %17, Token.value: %value.1 }
  [ %16 %value.1 %17 ]
  %19: ptr<i32> = offset %16 Token.kind
  [ %16 %value.1 %19 %17 ]
  store %19 %17
  [ %16 %value.1 ]
  %20: ptr<u8> = offset %16 Token.value
  [ %16 %20 %value.1 ]
  store %20 %value.1
  [ %16 ]
  ret %16
  [ ]
}

$fputc(%c: u8, %file: ptr<FILE>): i32

$malloc(%size: u64): ptr<Any>

$exit(%code: i32)
